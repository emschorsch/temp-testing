{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V33Q9wUDaSxJ"
      },
      "source": [
        "#### Copyright 2018 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CK6tFvW_HkQ1"
      },
      "source": [
        "# Adversarial Multi-task Learning\n",
        "Authors: Zhe Zhao, Ben Hutchinson, Andrew Zaldivar, Emanuel Schorsch, Jilin Chen, Alex Beutel, Margaret Mitchell\n",
        "\n",
        "***\n",
        "\n",
        "Click [here](https://colab.research.google.com/github/google/ml_fairness/blob/master/colabs/adversarial_multitask_learning.ipynb) to run this colab interactively on colab.research.google.com.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mBvSvmWw_WD2"
      },
      "source": [
        "## Summary of This Notebook\n",
        "\n",
        "This notebook demonstrates a handy technique for fairness, using Tensorflow:  adversarial multi-task learning.\n",
        "It covers some of the work in the paper ([arxiv](https://arxiv.org/pdf/1707.00075.pdf)):\n",
        "\n",
        "\u003e ``` Alex Beutel, Jilin Chen, Zhe Zhao, Ed H. Chi.  Data Decisions and Theoretical Implications when\n",
        "Adversarially Learning Fair Representations.  FAT/ML, 2017. ```\n",
        "\n",
        "For further notebooks walking through other fairness-relevant techniques, check out the [ML Fairness web page](https://developers.google.com/machine-learning/fairness-overview/).\n",
        "\n",
        "We first walk through how to set up a multi-task learning model in Tensorflow, then extend to the adversarial case, where we'll negate the gradient of one of the tasks.  This adversarial technique can be used to help remove the effect of signals that you don't want your model to pick up on, such as gender or sex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ezq9VJ8xcDEG"
      },
      "source": [
        "## Intro Statement of Problem\n",
        "\n",
        "Multi-task learning is a technique we can use in neural networks to make multiple predictions at the same time from the same model.\n",
        "For example, a multi-task learning model can be trained to make predictions for both education level and income from the same input features.\n",
        "\n",
        "This can be useful when the tasks are related, and so being able to make predictions about one helps with the ability to make predictions about the others.  In this colab, we walk through making predictions about sex and income."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nfT7hZInL_hw"
      },
      "source": [
        "## About the UCI Census Income (Adult) Data Set\n",
        "\n",
        "The data set used throughout this notebook comes from the [1994 Census Income database](https://archive.ics.uci.edu/ml/datasets/Census+Income). Here's some information about each feature:\n",
        "\n",
        "|Column Name|Type|Description|\n",
        "|:---|:---|:---|\n",
        "|age|Continuous|The age of the individual|\n",
        "|workclass|Categorical|The type of employer the individual has|\n",
        "|fnlwgt|Continuous|# of people census takers believe that observation represents|\n",
        "|education|Categorical|The highest level of education achieved for that individual|\n",
        "|education_num|Continuous|The highest level of education in numerical form|\n",
        "|marital_status|Categorical|Marital status of the individual|\n",
        "|occupation|Categorical|The occupation of the individual|\n",
        "|relationship|Categorical|Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried|\n",
        "|race|Categorical|White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black|\n",
        "|sex|Categorical|Female, Male|\n",
        "|capital_gain|Continuous|Capital gains recorded|\n",
        "|capital_loss|Continuous|Capital losses recorded|\n",
        "|hours_per_week|Continuous|Hours worked per week|\n",
        "|native_country|Categorical|Country of origin of the individual|\n",
        "|income|Categorical|Whether the person makes more than $50,000 annually|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W1v1xmJFGYq6"
      },
      "source": [
        "## Let's Get Started!\n",
        "\n",
        "We will read in and preprocess the data using basic Tensorflow functions under-the-hood.\n",
        "\n",
        "First, we'll import all the packages that we'll need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "ui87_mpmuIOo"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q git+https://github.com/google/ml_fairness\n",
        "  \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from ml_fairness import simple_multitask_model\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zCpQdNjguWKf"
      },
      "source": [
        "Now we'll copy the required data files from Google Cloud Storage to a local directory.\n",
        "\n",
        "To do this we'll first need to authenticate to Google Cloud Storage. Executing the following cell will generate a link which you'll need to follow to get a verification code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "Wva1HHOGubs-"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tU-kKl5uuf7v"
      },
      "source": [
        "Now we'll sync the data for the colab to a tmp directory from Google Cloud Storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "N01ZF8_dugsv"
      },
      "outputs": [],
      "source": [
        "project_id = 'mledu-fairness'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "gcs_bucket_name = 'mledu-fairness/colabs/multitask_learning'\n",
        "local_dir_name = '/tmp/multitask_learning'\n",
        "if not os.path.exists(local_dir_name):\n",
        "  print(\"creating dir %s\" % local_dir_name)\n",
        "  !mkdir {local_dir_name}\n",
        "  \n",
        "!gsutil rsync gs://{gcs_bucket_name} {local_dir_name}\n",
        "\n",
        "!ls -al {local_dir_name}  \n",
        "\n",
        "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
        "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
        "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
        "           \"income_bracket\"]\n",
        "\n",
        "TRAIN_FILE = os.path.join(local_dir_name, \"adult.data\")\n",
        "TEST_FILE = os.path.join(local_dir_name, \"adult.test\")\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_FILE, names=COLUMNS, \n",
        "                       skipinitialspace=True)\n",
        "test_df = pd.read_csv(TEST_FILE, names=COLUMNS, \n",
        "                      skipinitialspace=True, skiprows=1)\n",
        "\n",
        "print('UCI Census Income (Adult) Data Set loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z1gPLcyGKdNr"
      },
      "source": [
        "Run this cell to make plots look better than using their default settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "37D2KiBF5SvI"
      },
      "outputs": [],
      "source": [
        "file_contents = \"\"\"\n",
        "axes.linewidth: 1.5\n",
        "axes.grid: True\n",
        "axes.titlesize: x-large\n",
        "axes.labelsize: large\n",
        "axes.axisbelow: True\n",
        "axes.facecolor: F7F7F7\n",
        "\n",
        "axes.prop_cycle: cycler('color', ['4285F4', 'DB4437', '0F9D58', 'F4B400', '9E9E9E', 'D2691E', 'FF6347', '87CEEB', 'FFC0CB', '32CD32', 'DA70D6', '808000', 'FFD700'])\n",
        "\n",
        "font.size: 14\n",
        "font.family: sans-serif\n",
        "\n",
        "xtick.labelsize: large\n",
        "ytick.labelsize: large\n",
        "\n",
        "grid.linewidth: 1.5\n",
        "\n",
        "figure.autolayout: True\n",
        "figure.figsize: 10, 10\n",
        "figure.titleweight: bold\n",
        "\n",
        "legend.fontsize: large\n",
        "legend.loc: best\n",
        "legend.fancybox: True\n",
        "legend.facecolor: FAFBFC\n",
        "legend.frameon: True\n",
        "figure.dpi: 1000\n",
        "\n",
        "lines.linewidth: 2\n",
        "\n",
        "text.antialiased: True\n",
        "text.hinting : auto\n",
        "\"\"\"\n",
        "# Use a tempfile because matplotlib has to load a file by name or URL.\n",
        "f = tempfile.NamedTemporaryFile(delete=False)\n",
        "name = f.name\n",
        "f.write(file_contents)\n",
        "f.close()\n",
        "\n",
        "# Load the style sheet.\n",
        "plt.style.use(name)\n",
        "\n",
        "# Make plots bigger.\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
        "\n",
        "# Make plots higher resolution.\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UiALCOrhk8Qo"
      },
      "source": [
        "# Multi-task Learning\n",
        "\n",
        "Now let's define some of the constants that we'll use throughout the colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "5ZQI28eOzC6I"
      },
      "outputs": [],
      "source": [
        "# Multi-task variables ======================================================\n",
        "MAIN = \"main\"\n",
        "AUX = \"aux\"\n",
        "TASKS = (MAIN, AUX)\n",
        "IDS = \"ids\"\n",
        "WEIGHTS = \"weights\"\n",
        "# These names are built/assumed by multi-task.\n",
        "# defined here to access them in the output.\n",
        "H_MAIN = \"h_\" + MAIN\n",
        "H_AUX = \"h_\" + AUX\n",
        "W_MAIN = WEIGHTS + \"_\" + MAIN\n",
        "W_AUX = WEIGHTS + \"_\" + AUX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ieA94DVVORI"
      },
      "source": [
        "The basic idea behind Multi-task Learning (MTL) is to use the same model to make predictions about multiple variables.\n",
        "\n",
        "This might include a main variable you want to make predictions for, like income bracket; and another sensitive variable that you want -- or do not want -- to be related to the predictions for the main variable.\n",
        "\n",
        "This is often cast as a **main task** and **auxiliary tasks**.  \n",
        "\n",
        "The *main task* is what you'd like the model to perform best on.  \n",
        "\n",
        "The *auxiliary tasks* can help to improve performance on the main task, or change the way the parameters are learned for the main task.\n",
        "\n",
        "If the tasks are related, then sometimes the model can improve performance on several of the tasks, by considering them all at the same time.\n",
        "As we will see, we can also use multi-task learning to explicitly *discourage* the model from learning an auxiliary task, while doing well on a main task -- effectively reshaping the signal for the main task.\n",
        "\n",
        "First, will begin by defining two tasks:\n",
        "\n",
        "\n",
        "1.   Income bracket, the main task.\n",
        "2.   Sex, the auxiliary task.\n",
        "\n",
        "We set the main task to predict income bracket in two buckets -- \u003e 50K and \u003c= 50K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "m-QxqWdaW0ku"
      },
      "outputs": [],
      "source": [
        "train_df[MAIN] = (train_df[\"income_bracket\"].apply(\n",
        "    lambda x: \"\u003e50K\" in x)).astype(np.float32)\n",
        "test_df[MAIN] = (test_df[\"income_bracket\"].apply(\n",
        "    lambda x: \"\u003e50K\" in x)).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A4ABDpyRW-oX"
      },
      "source": [
        "Now we set up the auxiliary task, sex. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "9w4bTuF7W-I5"
      },
      "outputs": [],
      "source": [
        "train_df[AUX] = train_df[\"sex\"].apply(\n",
        "    lambda x: \"Male\" in x).astype(np.float32)\n",
        "test_df[AUX] = test_df[\"sex\"].apply(\n",
        "    lambda x: \"Male\" in x).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Tspq5SmwMz2"
      },
      "source": [
        "Now we remove the variables (tasks) that we are predicting from the input data -- without doing this, the model will be able to see the answers in its input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "XCCfLOtZwMG5"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop(['income_bracket', 'sex'], axis=1)\n",
        "test_df = test_df.drop(['income_bracket', 'sex'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XidcYy-wXaHc"
      },
      "source": [
        "Now we create train and test data for the multi-task setup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iRGnoeAanG8u"
      },
      "source": [
        "## Negative Sampling\n",
        "\n",
        "Now we're going to modify how we sample from the data by using a **sampling** technique. \n",
        "\n",
        "Using this technique, the data is sampled to balance the weight of _positive_ examples and _negative_ examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "JhE1xKlAYKEi"
      },
      "outputs": [],
      "source": [
        "# To balance the data set, call this function.\n",
        "def negative_sampling(labels, neg_pos_ratio):\n",
        "  weight = tf.where(\n",
        "      labels \u003e 0.5, tf.ones_like(labels), tf.ones_like(labels) * neg_pos_ratio)\n",
        "  if neg_pos_ratio \u003e 1.0:\n",
        "    pos_sample_rate = 1.0\n",
        "    neg_sample_rate = 1.0 / neg_pos_ratio\n",
        "  else:\n",
        "    pos_sample_rate = neg_pos_ratio\n",
        "    neg_sample_rate = 1.0\n",
        "  sampling = tf.random_uniform(labels.shape) \u003c tf.where(\n",
        "      labels\u003e0.5, \n",
        "      tf.ones_like(labels) * pos_sample_rate,\n",
        "      tf.ones_like(labels) * neg_sample_rate)\n",
        "  return weight, sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jFb4lrlrYB1"
      },
      "source": [
        "## FairAware Note\n",
        "\n",
        "The way that you sample from your data can influence your results. \n",
        "\n",
        "Training your model to pay more or less attention to different examples in your training data effects which variables it cares the most about.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O9H5CfaIaqFk"
      },
      "source": [
        "Next, we'll set up the `input_fn` for Tensorflow to read the data.\n",
        "\n",
        "Run this cell to load `input_fn` for handling the multi-task case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "QU7XIjn7YNeM"
      },
      "outputs": [],
      "source": [
        "def input_fn(df, batch_size=100, sampling_task_name=None):\n",
        "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
        "  # the values of that column stored in a constant Tensor.\n",
        "  continuous_columns = list(df.select_dtypes(exclude=['object']))\n",
        "  categorical_columns = list(df.select_dtypes(include=['object']))\n",
        "  continuous_cols = {k: tf.constant(df[k].values)\n",
        "                     for k in continuous_columns}\n",
        "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
        "  # to the values of that column stored in a tf.SparseTensor.\n",
        "  #scipy.sparse.csr_matrix(df.values)\n",
        "  categorical_cols = {k: tf.SparseTensor(\n",
        "      indices=[[i, 0] for i in range(df[k].size)],\n",
        "      values=df[k].values,\n",
        "      dense_shape=[df[k].size, 1])\n",
        "                      for k in categorical_columns}\n",
        "  # Merges the two dictionaries into one.\n",
        "  features = dict(continuous_cols.items() + categorical_cols.items())\n",
        "  # Convert the label column into a constant Tensor for each task.\n",
        "  targets = {k: tf.constant(df[k].values) for k in TASKS}\n",
        "  if batch_size \u003c= 0:\n",
        "    return features, targets\n",
        "  ids = tf.reshape(tf.where(tf.ones(shape=[len(df),]) \u003e 0), shape=[-1,])\n",
        "  inputs = {}\n",
        "  inputs.update(features)\n",
        "  inputs.update(targets)\n",
        "  inputs[IDS] = ids\n",
        "  if sampling_task_name:\n",
        "    neg_pos_ratio = (\n",
        "        float(len(df[sampling_task_name]) - sum(df[sampling_task_name])) /\n",
        "        sum(df[sampling_task_name]))\n",
        "    weight, sampling = negative_sampling(\n",
        "        inputs[sampling_task_name], neg_pos_ratio)\n",
        "    inputs[WEIGHTS] = tf.reshape(weight, shape=[-1, 1])\n",
        "    batched_inputs = tf.train.maybe_batch(\n",
        "        inputs, sampling, batch_size, enqueue_many=True)\n",
        "  else:\n",
        "    inputs[WEIGHTS] = tf.ones_like(shape=[len(df), 1])\n",
        "    batched_inputs = tf.train.batch(inputs, batch_size, enqueue_many=True)\n",
        " \n",
        "  batched_targets = {MAIN: tf.reshape(batched_inputs.pop(MAIN), shape=[-1, 1]), \n",
        "                     AUX: tf.reshape(batched_inputs.pop(AUX),\n",
        "                                         shape=[-1, 1])}\n",
        "  \n",
        "  return batched_inputs, batched_targets\n",
        "\n",
        "print('input_fn() loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qVAYa9-WnOTq"
      },
      "source": [
        "We next input the tasks corresponding to income and sex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "CBeNQJDqYWkz"
      },
      "outputs": [],
      "source": [
        "def make_multitask_input_fn(df, batch_sizes=[100, 100], tasks=TASKS):\n",
        "  def make_current_input_fn(df, batch_size, task):\n",
        "    def current_input_fn():\n",
        "      return input_fn(df, batch_size, task)\n",
        "    return current_input_fn\n",
        "  input_fn_dict = { task : make_current_input_fn(df, batch_size, task)\n",
        "                    for (batch_size, task) in zip(batch_sizes, tasks) }\n",
        "  return simple_multitask_model.merge_multiple_input_fn(input_fn_dict, WEIGHTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xQR9CsyNf5XK"
      },
      "source": [
        "Now we set up the `input_fn` for a few comparisons.\n",
        "\n",
        "We'll compare a baseline (single-task) with multi-task and adversarial multi-task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "CkNOCtgAdJD6"
      },
      "outputs": [],
      "source": [
        "base_train_input_fn = make_multitask_input_fn(\n",
        "    train_df, batch_sizes=[100], tasks=[MAIN])\n",
        "\n",
        "multi_train_input_fn = make_multitask_input_fn(\n",
        "    train_df, batch_sizes=[100, 100], tasks=TASKS)\n",
        "\n",
        "eval_input_fn = make_multitask_input_fn(\n",
        "    test_df, batch_sizes=[5000, 5000], tasks=TASKS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7iF3SBGf4tnK"
      },
      "source": [
        "Now let's define the tasks for the multi-task models, and initialize the weights and shared hidden units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "9DHm6lppYsd_"
      },
      "outputs": [],
      "source": [
        "# Dict mapping target/head names to the dimensionality of predicted targets.\n",
        "num_classes_tasks = {MAIN: 2, AUX: 2}\n",
        "\n",
        "task_names_dict = {MAIN: (H_MAIN, W_MAIN),\n",
        "                   AUX: (H_AUX, W_AUX)}\n",
        "# List of `_Head` instances.\n",
        "all_heads = []\n",
        "for task_name in (MAIN, AUX):\n",
        "    head_name = task_names_dict[task_name][0]\n",
        "    weight_column_name = task_names_dict[task_name][1]\n",
        "    multi_head = tf.contrib.learn.multi_class_head(\n",
        "        num_classes_tasks[task_name],\n",
        "        label_name=task_name,\n",
        "        head_name=head_name,\n",
        "        weight_column_name=weight_column_name)\n",
        "    all_heads.append(multi_head)\n",
        "shared_hidden_units = [64]\n",
        "hidden_units_dict = {H_MAIN: [], H_AUX: []}\n",
        "baseline_heads = [all_heads[0]]\n",
        "multi_heads = all_heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C3aVJgY3V1sY"
      },
      "source": [
        "Next, we get the features for our different variables.  We use a different formulation than above because this spot of code works with an older version of Tensorflow.\n",
        "\n",
        "Here, we work with an **embedding** for each variable.  This requires defining columns as either sparse or real-valued."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IIr4ET_uw-u6"
      },
      "source": [
        "## FairAware Note\n",
        "\n",
        "Below, we use `race` as an input feature.  \n",
        "\n",
        "This is a sensitive characteristic that may or may not make sense to include.\n",
        "\n",
        "Try removing this and see what changes.\n",
        "\n",
        "What other features might you use that are included/encompassed in what we think of as `race`, but are not sensitive?\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ol9g0KSIgtT"
      },
      "source": [
        "Run the cell below to load the feature columns function for the multi-task case. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "txkhOUgxWsVw"
      },
      "outputs": [],
      "source": [
        "# Get feature columns\n",
        "def get_feature_columns(embedding_dim=10):\n",
        "  race = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "      \"race\", hash_bucket_size=100)\n",
        "\n",
        "  education = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "      \"education\", hash_bucket_size=1000)\n",
        "  marital_status = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "      \"marital_status\", hash_bucket_size=100)\n",
        "  relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "      \"relationship\", hash_bucket_size=100)\n",
        "  workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "      \"workclass\", hash_bucket_size=100)\n",
        "  occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "      \"occupation\", hash_bucket_size=1000)\n",
        "  native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
        "      \"native_country\", hash_bucket_size=1000)\n",
        "\n",
        "  age = tf.contrib.layers.real_valued_column(\"age\")\n",
        "  age_buckets = tf.contrib.layers.bucketized_column(\n",
        "      age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "  education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
        "  capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
        "  capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
        "  hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")\n",
        "\n",
        "  education_embedding = tf.contrib.layers.embedding_column(\n",
        "      education, embedding_dim)\n",
        "  marital_status_embedding = tf.contrib.layers.embedding_column(\n",
        "      marital_status, embedding_dim)\n",
        "  relationship_embedding = tf.contrib.layers.embedding_column(\n",
        "      relationship, embedding_dim)\n",
        "  workclass_embedding = tf.contrib.layers.embedding_column(\n",
        "      workclass, embedding_dim)\n",
        "  occupation_embedding = tf.contrib.layers.embedding_column(\n",
        "      occupation, embedding_dim)\n",
        "  native_country_embedding = tf.contrib.layers.embedding_column(\n",
        "      native_country, embedding_dim)\n",
        "  \n",
        "  race_embedding = tf.contrib.layers.embedding_column(\n",
        "      race, embedding_dim)\n",
        "\n",
        "  feature_columns = [age_buckets, education_num, capital_gain,\n",
        "                     capital_loss, hours_per_week,\n",
        "                     education_embedding, marital_status_embedding, \n",
        "                     relationship_embedding, workclass_embedding, \n",
        "                     occupation_embedding, native_country_embedding]\n",
        "  # This is a sensitive characteristic!\n",
        "  feature_columns += [race_embedding]\n",
        "  return feature_columns\n",
        "\n",
        "print('get_feature_columns() loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oA09s3RCo4pV"
      },
      "source": [
        "Now set up the feature columns for some Tensorflow multi-taskin'!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "w0x14QYfWtK4"
      },
      "outputs": [],
      "source": [
        "feature_columns = get_feature_columns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "udgh5efFuq-P"
      },
      "source": [
        "Define some helper functions for creating the estimators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "a76oPDa_uwTa"
      },
      "outputs": [],
      "source": [
        "def train_op_fn(loss):\n",
        "  \"\"\"Returns the op to optimize the loss.\"\"\"\n",
        "  return tf.contrib.layers.optimize_loss(\n",
        "      loss, tf.contrib.framework.get_global_step(), 1.0, \"Adagrad\")\n",
        "\n",
        "def create_model_fn(feature_columns, heads, shared_hidden_units,\n",
        "                    hidden_units_dict, scale_gradient_targets_dict={}):\n",
        "  def model_fn(features, labels, mode):\n",
        "    targets_dict = {head.head_name: head.logits_dimension for head in heads}\n",
        "    predictions = simple_multitask_model.build_shared_bottom_model(\n",
        "        features,\n",
        "        feature_columns,\n",
        "        targets_dict,\n",
        "        shared_hidden_units,\n",
        "        hidden_units_dict,\n",
        "        is_training=(mode == tf.contrib.learn.ModeKeys.TRAIN),\n",
        "        activation_fn=tf.nn.relu,\n",
        "        scale_gradient_targets_dict=scale_gradient_targets_dict)\n",
        "    multihead = tf.contrib.learn.multi_head(heads)\n",
        "    return multihead.create_model_fn_ops(features, mode, labels, train_op_fn,\n",
        "                                      predictions, scale_gradient_targets_dict)\n",
        "  return model_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cGiPsIJZpJ_E"
      },
      "source": [
        "Now we can create the Estimators!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "JUCrdWcupL78"
      },
      "outputs": [],
      "source": [
        "estimator_base = tf.contrib.learn.Estimator(\n",
        "    create_model_fn(\n",
        "        feature_columns,\n",
        "        baseline_heads,\n",
        "        shared_hidden_units, \n",
        "        hidden_units_dict={H_MAIN: []}))\n",
        "\n",
        "estimator_multi = tf.contrib.learn.Estimator(\n",
        "    create_model_fn(\n",
        "        feature_columns,\n",
        "        multi_heads,\n",
        "        shared_hidden_units, \n",
        "        hidden_units_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y5kmyMMZutIL"
      },
      "source": [
        "# Adversarial Multi-task Learning\n",
        "\n",
        "To compare against a model trained adversarially, we scale the gradient of our chosen adversarial auxiliary task by a negative value.\n",
        "\n",
        "This negates the gradient for that task, backpropogating the negation through the network.\n",
        "\n",
        "This effectively tells the network that the *better* it is at making predictions for the auxiliary task, the more it should negate (penalize) the effect of the parameters driving the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "TVvMnFXbqFi1"
      },
      "outputs": [],
      "source": [
        "scale_gradient_targets_dict = {H_AUX: -0.01}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C_0GKpY3qH0c"
      },
      "source": [
        "Easy now using the learning.fairness.multitask module!  Now let's create the adversarial estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "EFLgimQEYxb6"
      },
      "outputs": [],
      "source": [
        "estimator_adv = tf.contrib.learn.Estimator(\n",
        "    create_model_fn(\n",
        "        feature_columns,\n",
        "        multi_heads,\n",
        "        shared_hidden_units, \n",
        "        hidden_units_dict,\n",
        "        scale_gradient_targets_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ILeBR084j3Mn"
      },
      "source": [
        "Now we'll step through training for 5 rounds (epochs), fitting the model again at every 300 steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "fP4Qnuk4wRU5"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "train_steps = 300\n",
        "\n",
        "# Hack to alter behavior when running unit tests.\n",
        "if 'COLAB_NOTEBOOK_TEST' in os.environ:\n",
        "  # Use a small number of steps when running unit tests, for faster\n",
        "  # tests and less memory usage.\n",
        "  train_steps = 2\n",
        "  num_epochs = 2\n",
        "  logging.info('Running in test mode, using %d steps and %d epochs' % (train_steps, num_epochs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dWx8i56Nwc3J"
      },
      "source": [
        "Each time we fit, we evaluate on the test set using the baseline and the adversarial network to predict the income bracket. \n",
        "\n",
        "We will calculate how well it's performing using the common metric **AUC**, or Area Under the Curve.\n",
        "\n",
        "The 'Curve' often refers to the [Receiver Operating Characteristic (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic), which is a handy thing to know about relevant to Fairness.\n",
        "\n",
        "The ROC curve measures the tradeoff between the False Positive Rate (FPR) and the True Positive Rate (TPR).\n",
        "\n",
        "True Positive Rate = 1 - False Negative Rate, so knowing the TPR also lets you know the FNR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rjxzb5PUtaCu"
      },
      "source": [
        "## FairAware Note\n",
        "\n",
        "The True Positive Rate/False Negative Rate and the False Positive Rate are metrics that let you know how much your model is incorrectly predicting a variable's value:\n",
        "\n",
        "* Failing to predict it (False Negative Rate), or \n",
        "* Over-predicting it (False Positive Rate).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "F63k_pLaY3eP"
      },
      "outputs": [],
      "source": [
        "def fit(estimator, train_input_fn, eval_input_fn, has_aux=False, train_steps=300, num_epochs=5):\n",
        "  loss_main_list = []\n",
        "  loss_aux_list = []\n",
        "  auc_main_list = []\n",
        "  auc_aux_list = []\n",
        "\n",
        "  # For each epoch, advances train_steps.\n",
        "  for i in range(num_epochs):\n",
        "    # Fit the model...\n",
        "    estimator.fit(input_fn=train_input_fn, steps=train_steps)\n",
        "    results = estimator.evaluate(input_fn=eval_input_fn, steps=1)\n",
        "\n",
        "    print(\"\\n=== Step %s:\" % (str((i+1)*train_steps)))\n",
        "    print(\"    AUC for main task: %s; main task loss: %s;\" %\n",
        "          (results[\"auc/\" + H_MAIN], results[\"loss/\" + H_MAIN]))\n",
        "    # AUC for income bracket. \n",
        "    auc_main_list.append(results[\"auc/\" + H_MAIN])\n",
        "    # Loss for income bracket.\n",
        "    loss_main_list.append(results[\"loss/\" + H_MAIN])\n",
        "    if has_aux:\n",
        "      print(\"    AUC for aux task: %s; aux task loss: %s;\" %\n",
        "            (results[\"auc/\" + H_AUX], results[\"loss/\" + H_AUX]))\n",
        "      # AUC for sex with the multi-task learning\n",
        "      auc_aux_list.append(results[\"auc/\" + H_AUX])\n",
        "      # Loss for sex with multi-task learning\n",
        "      loss_aux_list.append(results[\"loss/\" + H_AUX])\n",
        "  if has_aux:      \n",
        "      return auc_main_list, loss_main_list, auc_aux_list, loss_aux_list\n",
        "  else:\n",
        "    return auc_main_list, loss_main_list\n",
        "\n",
        "\n",
        "print(\"Fitting Baseline!\")\n",
        "base_out = fit(estimator_base, base_train_input_fn, eval_input_fn,\n",
        "               train_steps=train_steps, num_epochs=num_epochs)\n",
        "base_auc_main_list, base_loss_main_list = base_out\n",
        "\n",
        "print(\"Fitting Multi-task model!\")\n",
        "multi_out = fit(estimator_multi, multi_train_input_fn, eval_input_fn, has_aux=True,\n",
        "                train_steps=train_steps, num_epochs=num_epochs)\n",
        "multi_auc_main_list, multi_loss_main_list, multi_auc_aux_list, multi_loss_aux_list = multi_out\n",
        "\n",
        "print(\"Fitting Adversarial Multi-task model!\")\n",
        "adv_out = fit(estimator_adv, multi_train_input_fn, eval_input_fn, has_aux=True,\n",
        "              train_steps=train_steps, num_epochs=num_epochs)\n",
        "adv_auc_main_list, adv_loss_main_list, adv_auc_aux_list, adv_loss_aux_list = adv_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KhYVo1xRsIe0"
      },
      "source": [
        "Check out what's happened here:  The AUC for all models should have improved, and the loss should have gone down with each iteration.\n",
        "\n",
        "The baseline might achieve a higher AUC than the adversarial network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VwOoYvCjqrZm"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OAlhoACiqkBx"
      },
      "source": [
        "## Averaging Multiple Runs\n",
        "\n",
        "If you run this multiple times, each time it will be a bit different.\n",
        "In cases like this, we take the **average** over multiple runs. \n",
        "\n",
        "Because this is a colab, we'll just run it once.\n",
        "\n",
        "A general rule of thumb is to average over 5-10 runs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4LUZVMEh-CWL"
      },
      "source": [
        "We can visualize the change in the AUC between the models using matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "Ndo_CRgkdOD8"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "xax = [n for n in range(num_epochs)]\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.xlabel(\"Num Epochs\")\n",
        "plt.plot(xax, adv_auc_main_list, label=\"Adversarial Multi-task\")\n",
        "plt.plot(xax, multi_auc_main_list, label=\"Multi-task\")\n",
        "plt.plot(xax, base_auc_main_list, label=\"Baseline\")\n",
        "plt.xticks(xax)\n",
        "plt.legend(loc=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZQ_LFGWDuoL2"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Now let's get ready to evaluate.  We will store the false negatives in three variables:\n",
        "\n",
        "\n",
        "1.   Overall false negatives\n",
        "2.   False negatives for the label '0' (\u003e50K)\n",
        "3.   False negatives for the label '1' (\u003c=50K)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "woLlozNEYkqg"
      },
      "outputs": [],
      "source": [
        "# Counting numbers.\n",
        "def evaluate(estimator, input_fn, test_df, false_positive=True):\n",
        "  predictions = list(estimator.predict(\n",
        "      input_fn=lambda :input_fn(test_df, batch_size=-1)))\n",
        "  print(predictions)\n",
        "  \"\"\"Calculates values for the binary confusion matrix\"\"\"\n",
        "  n_0 = 0; n_1 = 0; pos = 0; neg = 0\n",
        "  tn = 0; tn_0 = 0; tn_1 = 0\n",
        "  tp = 0; tp_0 = 0; tp_1 = 0\n",
        "  fp = 0; fp_0 = 0; fp_1 = 0\n",
        "  fn = 0; fn_0 = 0; fn_1 = 0.0\n",
        "  # For each of the testing instances...\n",
        "  output_predictions = [dict_out[(H_MAIN, 'logistic')] for dict_out in predictions]\n",
        "  print(output_predictions)\n",
        "  for i in range(len(test_df)):\n",
        "    # If the ground truth is 0 for the aux task (sex),\n",
        "    # which means sex is '0'...\n",
        "    if test_df[AUX][i] == 0.0:\n",
        "      # Increment 0 count\n",
        "      n_0 += 1\n",
        "      if predictions[i][(H_MAIN, 'classes')] == int(test_df[MAIN][i]):\n",
        "        # If the ground truth is 0 for task 1 (income bracket),\n",
        "        # it's a 'negative' in a binary confusion matrix.\n",
        "        if test_df[MAIN][i] == 0.0:\n",
        "          tn_0 += 1; tn += 1; neg += 1\n",
        "        # Otherwise it's a positive.\n",
        "        else:\n",
        "          tp_0 += 1; tp += 1; pos += 1\n",
        "      else:\n",
        "        if test_df[MAIN][i] == 0.0:\n",
        "          fp_0 += 1; fp += 1; neg += 1\n",
        "        else:\n",
        "          fn_0 += 1; fn += 1; pos += 1\n",
        "    # When sex is '1'....\n",
        "    else:\n",
        "      # Increment 1 count\n",
        "      n_1 += 1\n",
        "      if predictions[i][(H_MAIN, 'classes')] == int(test_df[MAIN][i]):\n",
        "        if test_df[MAIN][i] == 0.0:\n",
        "          tn_1 += 1; tn += 1; neg += 1\n",
        "        else:\n",
        "          tp_1 += 1; tp += 1; pos += 1\n",
        "      else:\n",
        "        if test_df[MAIN][i] == 0.0:\n",
        "          fp_1 += 1; fp += 1; neg += 1\n",
        "        else:\n",
        "          fn_1 += 1; fn += 1; pos += 1\n",
        "  print(\"num pos %d, neg %d\" % (pos, neg))\n",
        "  print(\"num n_0 %d, n_1 %d\" % (n_0, n_1))\n",
        "  if false_positive:\n",
        "    normalized_false_positives = float(fp) / len(test_df)\n",
        "    fpr_0 = float(fp_0) / n_0\n",
        "    fpr_1 = float(fp_1) / n_1\n",
        "    return output_predictions, normalized_false_positives, fpr_0, fpr_1\n",
        "  else:\n",
        "    normalized_false_negatives = float(fn) / len(test_df)\n",
        "    fnr_0 = float(fn_0) / n_0\n",
        "    fnr_1 = float(fn_1) / n_1\n",
        "    return output_predictions, normalized_false_negatives, fnr_0, fnr_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g1IM0jxQd6tW"
      },
      "source": [
        "On to evaluating the baseline!  We're printing out some of the details to give you a sense of what's getting captured 'under the hood'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "ViGTa0giqTsC"
      },
      "outputs": [],
      "source": [
        "baseline_pred, baseline_fn, baseline_fn_0, baseline_fn_1 = evaluate(\n",
        "    estimator_base, input_fn, test_df, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8K3IRbFevHpT"
      },
      "source": [
        "Now we'll do the same for the multi-task networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "RPQmJ_2qvGm_"
      },
      "outputs": [],
      "source": [
        "multi_pred, multi_fn, multi_fn_0, multi_fn_1 = evaluate(\n",
        "    estimator_multi, input_fn, test_df, False)\n",
        "\n",
        "adv_pred, adv_fn, adv_fn_0, adv_fn_1 = evaluate(\n",
        "    estimator_adv, input_fn, test_df, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vl6KjckMvRS4"
      },
      "source": [
        "## Plotting Results\n",
        "\n",
        "Let's plot it to see the False Negative Rate on the income bracket predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "zHPO-wr2vTUk"
      },
      "outputs": [],
      "source": [
        "plt.bar([1, 3], [baseline_fn_0, baseline_fn_1], [0.4, 0.4], color='red', label=\"Baseline\");\n",
        "plt.bar([1.5, 3.5], [multi_fn_0, multi_fn_1], [0.4, 0.4], color='blue', label=\"Multi-task\");\n",
        "plt.bar([2, 4], [adv_fn_0, adv_fn_1], [0.4, 0.4], color='purple', label=\"Adversarial\");\n",
        "xax = ['Income Bracket \u003c 50K','Income Bracket \u003e= 50K']\n",
        "plt.xlim(0, 5)\n",
        "plt.ylabel(\"False Negative Rate\")\n",
        "plt.xticks([1.5, 3.5], xax)\n",
        "plt.legend(loc=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KMMfNIyyeaTC"
      },
      "source": [
        "You might see different kinds of results:  For example, the adversarial approach working better for one income bracket than the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Aas_jaWCvXI2"
      },
      "source": [
        "Now we'll do the same evaluation for False Positive Rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "9qpEWcgqvb7U"
      },
      "outputs": [],
      "source": [
        "base_pred, base_fp, base_fp_0, base_fp_1 = evaluate(\n",
        "    estimator_base, input_fn, test_df, True)\n",
        "\n",
        "multi_pred, multi_fp, multi_fp_0, multi_fp_1 = evaluate(\n",
        "    estimator_multi, input_fn, test_df, True)\n",
        "\n",
        "adv_pred, adv_fp, adv_fp_0, adv_fp_1 = evaluate(\n",
        "    estimator_adv, input_fn, test_df, True)\n",
        "\n",
        "plt.xlim(0, 5)\n",
        "plt.bar([1, 3], [base_fp_0, base_fp_1], [0.4, 0.4], color='red', label=\"Baseline\")\n",
        "plt.bar([1.5, 3.5], [multi_fp_0, multi_fp_1], [0.4, 0.4], color='blue', label=\"Multi-task\");\n",
        "plt.bar([2, 4], [adv_fp_0, adv_fp_1], [0.4, 0.4], color='purple', label=\"Adversarial\")\n",
        "xax = ['Income Bracket \u003c 50K','Income Bracket \u003e= 50']\n",
        "plt.ylabel(\"False Positive Rate\")\n",
        "plt.xticks([1.25, 3.25], xax) \n",
        "plt.legend(loc=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aycE0vQDfY7k"
      },
      "source": [
        "## FairAware Note\n",
        "\n",
        "There are trade-offs between different evaluation metrics, and what to prioritize depends on your application.  For example, a lower False Positive Rate might be more important for your application than a lower False Negative Rate.  You may care a lot about true negatives, and so prefer an overall accuracy metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VCkXWbzMGzbZ"
      },
      "source": [
        "To visualize how true positive rate and false positive rate trade-off, we can create a **receiver operating characteristic curve**, commonly called an ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "jk9PYFxMGpA2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, _ = roc_curve(test_df[MAIN], base_pred)\n",
        "fpr2, tpr2, _ = roc_curve(test_df[MAIN], multi_pred)\n",
        "fpr3, tpr3, _ = roc_curve(test_df[MAIN], adv_pred)\n",
        "\n",
        "def draw_roc(fpr, tpr, fpr2, tpr2, fpr3, tpr3, sweet_spot=False):\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, color='red', label='Baseline')\n",
        "  plt.plot(fpr2, tpr2, color='blue', label='Multitask')\n",
        "  plt.plot(fpr3, tpr3, color='purple', label='Adversarial')\n",
        "  if sweet_spot:\n",
        "    plt.plot(sweet_spot[0], sweet_spot[1], 'bo', color='orange', label='Sweet Spot!')\n",
        "  plt.legend(loc=4)\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver operating characteristic for income.')\n",
        "  plt.show()\n",
        "\n",
        "draw_roc(fpr, tpr, fpr2, tpr2, fpr3, tpr3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "default_view": {},
      "name": "ML Fairness: Multi-task Learning",
      "provenance": [
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir_multitask_external.ipynb?workspaceId=emschorsch:colab_external:875:citc",
          "timestamp": 1518901512727
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir_multitask_external.ipynb",
          "timestamp": 1518753078050
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir-multitask.ipynb",
          "timestamp": 1515117525617
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir-multitask.ipynb",
          "timestamp": 1514418443025
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir-multitask.ipynb?workspaceId=mmitchellai%3Aml-fairness%3A201%3Acitc",
          "timestamp": 1513636685396
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir-multitask.ipynb",
          "timestamp": 1513634680068
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir-multitask.ipynb",
          "timestamp": 1512512090157
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir-multitask.ipynb",
          "timestamp": 1512155213427
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/colabs/tensorflow/multitask/sir-multitask.ipynb",
          "timestamp": 1509144294315
        },
        {
          "file_id": "/piper/depot/google3/learning/fairness/multitask/uci_census_multitask_fairness.ipynb",
          "timestamp": 1508825588939
        },
        {
          "file_id": "0B8ek3lQeAABgbVVOSE1nUU1sNXM",
          "timestamp": 1504848036213
        }
      ],
      "toc_visible": true,
      "version": "0.3.2",
      "views": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
